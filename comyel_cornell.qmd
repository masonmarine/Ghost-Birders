---
title: "ebird_best_practices"
format: html
editor: visual

reference documentation url: https://cornelllabofornithology.github.io/ebird-best-practices/ebird.html 
---

## 2.2 Data extraction with auk

```{r}
library(auk)
library(dplyr)
library(ebirdst)
library(fields)
library(ggplot2)
library(gridExtra)
library(lubridate)
library(mccf1)
library(ranger)
library(readr)
library(scam)
library(sf)
library(terra)
library(tidyr)

# set random number seed for reproducibility
set.seed(1)

```

```{r}
# preparing files according to Cornell 2.2 
ebd <- auk_ebd("data-raw/comyel_2024.txt", 
               file_sampling = "data-raw/ebd_US-NC_comyel_smp_relSep-2024_sampling.txt")

# creating filter to complete checklist
ebd_filters <- ebd |>
  auk_complete()
```

```{r}
# output files
data_dir <- "data-raw"
if (!dir.exists(data_dir)) {
  dir.create(data_dir)
}

# create file paths forauk_sampling instead of just reading in as dbf 
f_ebd_cornell <- file.path(data_dir, "comyel_2024_cornell.txt")
f_sampling_cornell <- file.path(data_dir, "ebd_checklists_comyel_cornell.txt")

# only run if the files don't already exist
if (!file.exists(f_ebd_cornell)) {
  auk_filter(ebd_filters, file = f_ebd_cornell, file_sampling = f_sampling_cornell)
}
```

```{r}
# creating file paths instead of dbfs(which is what eBird documentation does through f_ebd and f_sed)
#f_ebd_cornell <- file.path("data-raw", "data-raw/comyel_2024.txt")

#f_sed_cornell <- file.path("data-raw", "data-raw/ebd_US-NC_comyel_smp_relSep-2024_sampling.txt")

# applying same filter to both obs and sampling files 
#auk_filter(ebd_filters, file = f_ebd_cornell, file_sampling = f_sed_cornell, overwrite = TRUE)
```

## 2.3 Importing and zero-filling

```{r}
ebd_zf <- auk_zerofill(f_ebd_cornell, f_sampling_cornell, collapse = TRUE)
```

Convert 'x' to NA

```{r}
# function to convert time observation to hours since midnight
time_to_decimal <- function(x) {
  x <- hms(x, quiet = TRUE)
  hour(x) + minute(x) / 60 + second(x) / 3600
}

# clean up variables
ebd_zf <- ebd_zf %>% 
  mutate(
    # convert X to NA
    observation_count = if_else(observation_count == "X", 
                                NA_character_, observation_count),
    observation_count = as.integer(observation_count),
    # effort_distance_km to 0 for non-travelling counts
    effort_distance_km = if_else(protocol_type != "Traveling", 
                                 0, effort_distance_km),
    # convert time to decimal hours since midnight
    time_observations_started = time_to_decimal(time_observations_started),
    # split date into year and day of year
    year = year(observation_date),
    day_of_year = yday(observation_date)
  )
```

## 2.4 Accounting for variation in detectability

```{r}
# additional filtering
ebd_zf_filtered <- ebd_zf %>% 
  filter(
    # checklists less than 5 hours long and 5 km in length, based on documentation suggestion
    duration_minutes <= 5 * 60,
    effort_distance_km <= 5,
    # after 1960
    year >= 1960)
```

Removing redundant variables

```{r}
ebird <- ebd_zf_filtered %>% 
  select(checklist_id, observer_id, sampling_event_identifier,
         scientific_name,
         observation_count, species_observed, 
         state_code, locality_id, latitude, longitude,
         protocol_type, all_species_reported,
         observation_date, year, day_of_year,
         time_observations_started, 
         duration_minutes, effort_distance_km,
         number_observers)

# write csv 
write_csv(ebird, "data_processed_cornell/ebd_comyel_zf.csv", na = "")
```

## 6 Data preparation

```{r}
library(lubridate)
library(sf)
library(raster)
library(dggridR)
library(pdp)
library(mgcv)
library(fitdistrplus)
library(viridis)
library(fields)
library(tidyverse)
# resolve namespace conflicts
select <- dplyr::select
map <- purrr::map
projection <- raster::projection

# set random number seed to insure fully repeatable results
set.seed(1)

# setup output directory for saved results
if (!dir.exists("output")) {
  dir.create("output")
}

# ebird data
ebird <- read_csv("data_processed_cornell/ebd_comyel_zf.csv") %>% 
  mutate(protocol_type = factor(protocol_type, 
                                levels = c("Stationary" , "Traveling"))) %>%
  # remove observations with no count
  filter(!is.na(observation_count))

# modis habitat covariates
#habitat <- read_csv("data/pland-elev_location-year.csv") %>% 
#  mutate(year = as.integer(year))

# combine ebird and habitat data
#ebird_habitat <- inner_join(ebird, habitat, by = c("locality_id", "year"))

# prediction surface
#pred_surface <- read_csv("data/pland-elev_prediction-surface.csv")
# latest year of landcover data
#max_lc_year <- pred_surface$year[1]
#r <- raster("data/prediction-surface.tif")

# load gis data for making maps

```
